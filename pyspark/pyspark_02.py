# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jF0fBgNfnjGrPosPBeEV1Gx6mcuoeV81
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType

spark = SparkSession.builder.appName("AdvancedPySpark").getOrCreate()

# Dữ liệu mẫu
data = [
    ("An", 25, 5000),
    ("Bình", 30, 7000),
    ("Cường", 22, 3000),
    ("Dung", 28, 6000),
    ("Hà", 35, 8000)
]
columns = ["Name", "Age", "Revenue"]
df = spark.createDataFrame(data, columns)

# Hàm Python để phân loại doanh thu
def revenue_category(revenue):
    if revenue > 6000:
        return "High"
    elif revenue > 4000:
        return "Medium"
    else:
        return "Low"

# Đăng ký UDF
revenue_category_udf = udf(revenue_category, StringType())

# Áp dụng UDF vào DataFrame
df_with_category = df.withColumn("RevenueCategory", revenue_category_udf(df.Revenue))
df_with_category.show()

# Dữ liệu mẫu với null
data_with_null = [
    ("An", 25, 5000),
    ("Bình", None, 7000),
    ("Cường", 22, None),
    ("Dung", 28, 6000),
    (None, 35, 8000)
]
columns = ["Name", "Age", "Revenue"]
df_null = spark.createDataFrame(data_with_null, columns)

df_null.show()

# 1. Phát hiện null
from pyspark.sql.functions import col, count, when

df_null.select([count(when(col(c).isNull(),c)).alias(c) for c in df_null.columns]).show()

# 2. Loại bỏ hàng chứa null
df_no_null = df_null.na.drop()
df_no_null.show()

# - Thay null trong cột Name bằng "Unknown"
df_filled = df_null.fillna({"Name": "Chưa có"})
df_filled.show()

# - Thay null trong cột Age bằng trung bình tuổi
avg_age = df_null.select("Age").na.drop().agg({"Age":"avg"}).collect()[0][0]
print(avg_age)
df_filled = df_null.fillna({"Age": avg_age})
df_filled = df_null.na.fill(avg_age, ["Age"])
df_filled.show()

# - Thay null trong cột Revenue bằng 0
df_filled = df_null.fillna({"Revenue": 0})
df_filled.show()

# - Thay null trong cột Name bằng "Unknown"
# - Thay null trong cột Age bằng trung bình tuổi
# - Thay null trong cột Revenue bằng 0
df_filled = df_null.fillna({"Age": avg_age,"Name":"Unknown","Revenue": 0})
df_filled.show()

from pyspark.sql.functions import when

# Phân loại doanh thu bằng when
df_with_when = df.withColumn(
    "RevenueCategory",
    when(col("Revenue") > 6000, "High")
    .when(col("Revenue") > 4000, "Medium")
    .otherwise("Low")
)
df_with_when.show()

# Gán giá trị mặc định cho null bằng when
df_null.show()
df_null_handled = df_null.withColumn(
    "Age",
    when(col("Age").isNull(), 30).otherwise(col("Age"))
)
df_null_handled.show()

from pyspark.sql.window import Window
from pyspark.sql.functions import rank, row_number, sum



# Định nghĩa Window
window_spec_row = Window.orderBy(col("Revenue").desc())
window_spec_rank = Window.orderBy(col("Name"))
# Thêm cột xếp hạng
df_with_rank = df.withColumn("Rank", rank().over(window_spec_rank))\
  .withColumn("RowNumber", row_number().over(window_spec_row))
df_with_rank.show()

# Window với doanh thu
window_revenue_total = Window.orderBy("Age").rowsBetween(Window.unboundedPreceding, Window.currentRow)

# Thêm cột tổng doanh thu
window_revenue_total = df.withColumn(
    "RevenueTotalRevenue",
    sum(col("Revenue")).over(window_revenue_total)
)
window_revenue_total.show()

# Thêm cột AgeGroup
df_with_age_group = df.withColumn(
    "AgeGroup",
    when(col("Age") < 30, "Young").otherwise("Adult")
)

# Window theo AgeGroup
window_by_age_group = Window.partitionBy("AgeGroup").orderBy(col("Revenue").desc())

# Xếp hạng trong mỗi AgeGroup
df_with_group_rank = df_with_age_group.withColumn(
    "RankInGroup",
    rank().over(window_by_age_group)
)
df_with_group_rank.show()